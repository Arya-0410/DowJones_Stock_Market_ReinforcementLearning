{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977-09-02</td>\n",
       "      <td>872.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1977-09-09</td>\n",
       "      <td>857.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1977-09-16</td>\n",
       "      <td>856.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1977-09-23</td>\n",
       "      <td>839.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1977-09-30</td>\n",
       "      <td>847.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Value\n",
       "0  1977-09-02  872.31\n",
       "1  1977-09-09  857.04\n",
       "2  1977-09-16  856.81\n",
       "3  1977-09-23  839.14\n",
       "4  1977-09-30  847.11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'DowJones.csv'\n",
    "stock_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Date column to datetime and set it as the index\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "stock_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the stock values to visualize trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_data.index, stock_data['Value'], label='Stock Value', color='blue')\n",
    "plt.title('Stock Value Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "# Decompose the time series\n",
    "result = seasonal_decompose(stock_data['Value'], model='additive', period=12)  # Adjust period based on your data frequency\n",
    "\n",
    "# Plot decomposition results\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test Statistic': 1.1566359672018125,\n",
       " 'p-value': 0.9956721479952785,\n",
       " 'Lags Used': 25,\n",
       " 'Number of Observations': 2056,\n",
       " 'Critical Values': {'1%': -3.4335345735350664,\n",
       "  '5%': -2.862946794168607,\n",
       "  '10%': -2.567518913543354},\n",
       " 'Is Stationary': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_test = adfuller(stock_data['Value'])\n",
    "\n",
    "p_value= adf_test[1]\n",
    "\n",
    "# Extract and display the results\n",
    "adf_results = {\n",
    "    'Test Statistic': adf_test[0],\n",
    "    'p-value': adf_test[1],\n",
    "    'Lags Used': adf_test[2],\n",
    "    'Number of Observations': adf_test[3],\n",
    "    'Critical Values': adf_test[4],\n",
    "    'Is Stationary': p_value < 0.05\n",
    "}\n",
    "adf_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADF Test Statistic (Differenced)': -8.09789828282761,\n",
       " 'p-value (Differenced)': 1.3237926974744794e-12,\n",
       " 'Critical Values (Differenced)': {'1%': -3.4335345735350664,\n",
       "  '5%': -2.862946794168607,\n",
       "  '10%': -2.567518913543354},\n",
       " 'Is Stationary (Differenced)': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply first-order differencing to make the series stationary\n",
    "stock_data['Value_diff'] = stock_data['Value'].diff()\n",
    "\n",
    "# Drop the first NaN value resulting from differencing\n",
    "differenced_data = stock_data.dropna()\n",
    "\n",
    "# Re-check stationarity with ADF test after differencing\n",
    "adf_result_diff = adfuller(differenced_data['Value_diff'])\n",
    "adf_test_statistic_diff, p_value_diff, critical_values_diff = adf_result_diff[0], adf_result_diff[1], adf_result_diff[4]\n",
    "\n",
    "# Display ADF test results for differenced data\n",
    "{\n",
    "    \"ADF Test Statistic (Differenced)\": adf_test_statistic_diff,\n",
    "    \"p-value (Differenced)\": p_value_diff,\n",
    "    \"Critical Values (Differenced)\": critical_values_diff,\n",
    "    \"Is Stationary (Differenced)\": p_value_diff < 0.05\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data['Value_diff'].isnull().any():\n",
    "    stock_data = stock_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "# Decompose the time series\n",
    "result = seasonal_decompose(stock_data['Value_diff'], model='additive', period=12)  # Adjust period based on your data frequency\n",
    "\n",
    "# Plot decomposition results\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Plot Autocorrelation\n",
    "plot_acf(stock_data['Value_diff'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1. Stabilize Variance (if needed)\n",
    "stock_data['Value_diff'] = np.log1p(stock_data['Value_diff'])  # Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train Data Size': 1664, 'Test Data Size': 417}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "train_size = int(len(differenced_data) * 0.8)\n",
    "train_data, test_data = differenced_data[:train_size], differenced_data[train_size:]\n",
    "\n",
    "# Check the sizes of train and test sets\n",
    "{\n",
    "    \"Train Data Size\": len(train_data),\n",
    "    \"Test Data Size\": len(test_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model's performance and return metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Array of true values\n",
    "    - y_pred: Array of predicted values\n",
    "    - model_name: Name of the model\n",
    "    - verbose: Whether to print results\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    metrics = {\"Model\": model_name, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape}\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"{model_name} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4%}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Value_diff'].isna().sum())  # Check for NaNs\n",
    "print(test_data['Value_diff'].isna().sum())   # Check for NaNs\n",
    "print(np.isinf(train_data['Value_diff']).sum())  # Check for Infs\n",
    "print(np.isinf(test_data['Value_diff']).sum())   # Check for Infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = stock_data.replace([np.inf, -np.inf], np.nan)  # Replace infinity with NaN\n",
    "stock_data = stock_data.dropna()  # Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (24.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-optimize) (24.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA order: [1, 1, 0] with RMSE: 258.1312331523514\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def arima_objective(order, train_data, test_data):\n",
    "    try:\n",
    "        model = ARIMA(train_data, order=order).fit()\n",
    "        forecast = model.forecast(len(test_data))\n",
    "        metrics = evaluate_model(test_data, forecast, f\"ARIMA Order {order}\", verbose=False)\n",
    "        if np.isnan(metrics[\"RMSE\"]) or np.isinf(metrics[\"RMSE\"]):\n",
    "            print(f\"Invalid RMSE for ARIMA({order}): {metrics['RMSE']}\")\n",
    "            return np.inf\n",
    "        return metrics[\"RMSE\"]  # Minimizing RMSE\n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA failed for order {order} with error: {e}\")\n",
    "        return np.inf\n",
    "\n",
    "# Bayesian Optimization for ARIMA\n",
    "from skopt.space import Integer\n",
    "\n",
    "search_space = [\n",
    "    Integer(0, 3, name=\"p\"),\n",
    "    Integer(0, 3, name=\"d\"),\n",
    "    Integer(0, 3, name=\"q\")\n",
    "]\n",
    "\n",
    "from skopt import gp_minimize\n",
    "\n",
    "def arima_bayesian_optimization(train_data, test_data):\n",
    "    def objective(params):\n",
    "        p, d, q = params\n",
    "        return arima_objective((p, d, q), train_data, test_data)\n",
    "    \n",
    "    result = gp_minimize(objective, search_space, n_calls=20, random_state=42)\n",
    "    best_order = result.x\n",
    "    print(f\"Best ARIMA order: {best_order} with RMSE: {result.fun}\")\n",
    "    return best_order\n",
    "\n",
    "# Example Usage\n",
    "best_arima_order = arima_bayesian_optimization(train_data['Value_diff'], test_data['Value_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SARIMA parameters: [3, 1, 1, 1, 0, 0, 17] with RMSE: 259.0269789231441\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Define SARIMA objective\n",
    "def sarima_objective(params, train_data, test_data):\n",
    "    try:\n",
    "        p, d, q, P, D, Q, s = params\n",
    "        model = SARIMAX(train_data, \n",
    "                        order=(int(p), int(d), int(q)), \n",
    "                        seasonal_order=(int(P), int(D), int(Q), int(s)),\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False).fit(disp=False)\n",
    "        forecast = model.forecast(steps=len(test_data))\n",
    "        metrics = evaluate_model(test_data, forecast.values, f\"SARIMA({params})\", verbose=False)\n",
    "        return metrics[\"RMSE\"]\n",
    "    except:\n",
    "        return np.inf\n",
    "\n",
    "# Bayesian Optimization for SARIMA\n",
    "search_space = [\n",
    "    Integer(0, 3, name=\"p\"), Integer(0, 2, name=\"d\"), Integer(0, 3, name=\"q\"),\n",
    "    Integer(0, 3, name=\"P\"), Integer(0, 2, name=\"D\"), Integer(0, 3, name=\"Q\"),\n",
    "    Integer(12, 24, name=\"s\")  # Seasonal period\n",
    "]\n",
    "\n",
    "def sarima_bayesian_optimization(train_data, test_data):\n",
    "    def objective(params):\n",
    "        return sarima_objective(params, train_data, test_data)\n",
    "    \n",
    "    result = gp_minimize(objective, search_space, n_calls=20, random_state=42)\n",
    "    best_params = result.x\n",
    "    print(f\"Best SARIMA parameters: {best_params} with RMSE: {result.fun}\")\n",
    "    return best_params\n",
    "\n",
    "# Train and Evaluate SARIMA\n",
    "best_sarima_params = sarima_bayesian_optimization(train_data['Value_diff'], test_data['Value_diff'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arch in c:\\users\\pc\\anaconda3\\lib\\site-packages (7.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from arch) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from arch) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from arch) (2.1.4)\n",
      "Requirement already satisfied: statsmodels>=0.12 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from arch) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas>=1.4->arch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas>=1.4->arch) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas>=1.4->arch) (2023.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from statsmodels>=0.12->arch) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from statsmodels>=0.12->arch) (24.1)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.12->arch) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\2477198581.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['stabilized'] = np.log(train_data['Value_diff'])\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\2477198581.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['stabilized'] = np.log(test_data['Value_diff'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters [4, 2]: \n",
      "Error with parameters [4, 3]: \n",
      "Error with parameters [3, 1]: \n",
      "Error with parameters [3, 2]: \n",
      "Error with parameters [2, 4]: \n",
      "Error with parameters [1, 4]: \n",
      "Error with parameters [5, 1]: \n",
      "Error with parameters [5, 3]: \n",
      "Error with parameters [3, 1]: \n",
      "Error with parameters [1, 3]: \n",
      "Error with parameters [5, 5]: \n",
      "Error with parameters [1, 5]: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [1, 3]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [4, 4]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters [1, 3]: \n",
      "Error with parameters [4, 4]: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [2, 2]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [2, 1]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters [2, 2]: \n",
      "Error with parameters [2, 1]: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [3, 4]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [2, 2]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters [3, 4]: \n",
      "Error with parameters [2, 2]: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [4, 2]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [5, 5] before, using random point [3, 4]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters [4, 2]: \n",
      "Error with parameters [3, 4]: \n",
      "Best GARCH(p, q): [4, 2] with RMSE: 1000000.0\n"
     ]
    }
   ],
   "source": [
    "from arch import arch_model\n",
    "\n",
    "train_data['stabilized'] = np.log(train_data['Value_diff'])\n",
    "test_data['stabilized'] = np.log(test_data['Value_diff'])\n",
    "\n",
    "# Define the objective function for GARCH\n",
    "def garch_objective(params, train_data, test_data):\n",
    "    try:\n",
    "        p, q = params\n",
    "        model = arch_model(train_data, vol=\"Garch\", p=p, q=q).fit(disp=\"off\")\n",
    "        forecast = model.forecast(horizon=len(test_data)).mean.iloc[-1]\n",
    "        metrics = evaluate_model(test_data, forecast.values, f\"GARCH(p={p}, q={q})\", verbose=False)\n",
    "        return metrics[\"RMSE\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error with parameters {params}: {e}\")\n",
    "        return 1e6\n",
    "\n",
    "# Bayesian Optimization for GARCH\n",
    "search_space = [\n",
    "    Integer(1, 5, name=\"p\"),\n",
    "    Integer(1, 5, name=\"q\")\n",
    "]\n",
    "\n",
    "def garch_bayesian_optimization(train_data, test_data):\n",
    "    def objective(params):\n",
    "        return garch_objective(params, train_data, test_data)\n",
    "    \n",
    "    result = gp_minimize(objective, search_space, n_calls=20, random_state=42)\n",
    "    best_pq = result.x\n",
    "    print(f\"Best GARCH(p, q): {best_pq} with RMSE: {result.fun}\")\n",
    "    return best_pq\n",
    "\n",
    "# Example Usage\n",
    "best_garch_params = garch_bayesian_optimization(train_data['Value_diff'], test_data['Value_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters ['mul', 'mul', 13]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters ['mul', 'mul', 14]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters ['mul', 'add', 21]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters ['mul', 'mul', 12]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters ['add', 'mul', 17]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters ['add', 'mul', 17]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n",
      "Error with parameters [None, 'mul', 22]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [None, 'add', 18] before, using random point ['mul', 'mul', 16]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with parameters ['mul', 'mul', 16]: endog must be strictly positive when usingmultiplicative trend or seasonal components.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [None, 'add', 18] before, using random point ['add', 'add', 17]\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ETS parameters: ['add', None, 15] with RMSE: 259.16931998200596\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from skopt.space import Categorical, Integer\n",
    "\n",
    "# Define ETS objective\n",
    "\n",
    "    \n",
    "def ets_objective(params, train_data, test_data):\n",
    "    try:\n",
    "        trend, seasonal, seasonal_periods = params\n",
    "        model = ExponentialSmoothing(train_data, \n",
    "                                     trend=trend, \n",
    "                                     seasonal=seasonal, \n",
    "                                     seasonal_periods=int(seasonal_periods)).fit()\n",
    "        forecast = model.forecast(steps=len(test_data))\n",
    "        metrics = evaluate_model(test_data, forecast, f\"ETS({params})\", verbose=False)\n",
    "        return metrics[\"RMSE\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error with parameters {params}: {e}\")\n",
    "        return 1e6\n",
    "\n",
    "\n",
    "# Bayesian Optimization for ETS\n",
    "search_space = [\n",
    "    Categorical(['add', 'mul', None], name=\"trend\"),\n",
    "    Categorical(['add', 'mul', None], name=\"seasonal\"),\n",
    "    Integer(12, 24, name=\"seasonal_periods\")\n",
    "]\n",
    "\n",
    "def ets_bayesian_optimization(train_data, test_data):\n",
    "    def objective(params):\n",
    "        return ets_objective(params, train_data, test_data)\n",
    "    \n",
    "    result = gp_minimize(objective, search_space, n_calls=20, random_state=42)\n",
    "    best_params = result.x\n",
    "    print(f\"Best ETS parameters: {best_params} with RMSE: {result.fun}\")\n",
    "    return best_params\n",
    "\n",
    "# Train and Evaluate ETS\n",
    "best_ets_params = ets_bayesian_optimization(train_data['Value_diff'], test_data['Value_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (3.8.0)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (2.1.4)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (0.61)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (4.65.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pc\\anaconda3\\lib\\site-packages (from prophet) (6.4.5)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\pc\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Prophet Seasonality: None with RMSE: inf\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Define the objective function for Prophet\n",
    "def prophet_objective(seasonality_mode, train_data, test_data):\n",
    "    try:\n",
    "        model = Prophet(seasonality_mode=seasonality_mode, yearly_seasonality=True)\n",
    "        model.fit(train_data.rename(columns={'Value_diff': 'y'}))\n",
    "        future = model.make_future_dataframe(periods=len(test_data))\n",
    "        forecast = model.predict(future).iloc[-len(test_data):]['yhat']\n",
    "        metrics = evaluate_model(test_data, forecast.values, f\"Prophet({seasonality_mode})\", verbose=False)\n",
    "        return metrics[\"RMSE\"]\n",
    "    except:\n",
    "        return np.inf\n",
    "\n",
    "# Bayesian Optimization for Prophet\n",
    "search_space = ['additive', 'multiplicative']\n",
    "\n",
    "def prophet_bayesian_optimization(train_data, test_data):\n",
    "    best_rmse = float('inf')\n",
    "    best_mode = None\n",
    "    for mode in search_space:\n",
    "        rmse = prophet_objective(mode, train_data, test_data)\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_mode = mode\n",
    "    print(f\"Best Prophet Seasonality: {best_mode} with RMSE: {best_rmse}\")\n",
    "    return best_mode\n",
    "\n",
    "# Example Usage\n",
    "best_prophet_mode = prophet_bayesian_optimization(train_data, test_data['Value_diff'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\pc\\anaconda3\\lib\\site-packages (4.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (1.14.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\pc\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\pc\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_data['Denoised'] = stock_data['Denoised'].fillna(method='bfill').fillna(method='ffill')\n",
      "[I 2024-12-12 21:20:31,996] A new study created in memory with name: no-name-6cc1fe30-d716-409e-a7be-4f422d96364e\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:20:42,607] Trial 0 finished with value: 1.0615705604400352 and parameters: {'lstm_units': 118, 'dropout_rate': 0.10937882509736277, 'learning_rate': 0.00027957324709015175, 'seq_length': 13, 'batch_size': 58}. Best is trial 0 with value: 1.0615705604400352.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:20:53,408] Trial 1 finished with value: 1.063610396043725 and parameters: {'lstm_units': 128, 'dropout_rate': 0.49531092073269456, 'learning_rate': 0.006990129519905658, 'seq_length': 18, 'batch_size': 89}. Best is trial 0 with value: 1.0615705604400352.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002024A518720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:03,363] Trial 2 finished with value: 1.0586957011051248 and parameters: {'lstm_units': 128, 'dropout_rate': 0.24956453351908212, 'learning_rate': 0.0029278232622636873, 'seq_length': 16, 'batch_size': 37}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:11,413] Trial 3 finished with value: 1.0608648548776356 and parameters: {'lstm_units': 44, 'dropout_rate': 0.30171001596808844, 'learning_rate': 0.0044305675156357605, 'seq_length': 16, 'batch_size': 118}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:19,920] Trial 4 finished with value: 1.0937795535050638 and parameters: {'lstm_units': 57, 'dropout_rate': 0.3941694253047424, 'learning_rate': 0.00046664770686748614, 'seq_length': 12, 'batch_size': 93}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:31,657] Trial 5 finished with value: 1.0735223896439505 and parameters: {'lstm_units': 115, 'dropout_rate': 0.4896496777332028, 'learning_rate': 0.0005556626945199539, 'seq_length': 32, 'batch_size': 85}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002024AAD6980> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:43,600] Trial 6 finished with value: 1.1122553300220843 and parameters: {'lstm_units': 84, 'dropout_rate': 0.4677445965339624, 'learning_rate': 0.004029908362091604, 'seq_length': 47, 'batch_size': 127}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:21:51,494] Trial 7 finished with value: 1.1159074469210306 and parameters: {'lstm_units': 36, 'dropout_rate': 0.22456236860001125, 'learning_rate': 0.00025317340776762884, 'seq_length': 23, 'batch_size': 80}. Best is trial 2 with value: 1.0586957011051248.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:22:05,834] Trial 8 finished with value: 1.0493632906145054 and parameters: {'lstm_units': 127, 'dropout_rate': 0.44536224808497094, 'learning_rate': 0.002815783579186889, 'seq_length': 48, 'batch_size': 126}. Best is trial 8 with value: 1.0493632906145054.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:22:17,778] Trial 9 finished with value: 1.0606877355488027 and parameters: {'lstm_units': 50, 'dropout_rate': 0.4584189538628156, 'learning_rate': 0.0008814259147170272, 'seq_length': 29, 'batch_size': 32}. Best is trial 8 with value: 1.0493632906145054.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:22:29,803] Trial 10 finished with value: 1.0216786848805979 and parameters: {'lstm_units': 97, 'dropout_rate': 0.377157247439672, 'learning_rate': 0.0015679764700239909, 'seq_length': 48, 'batch_size': 109}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:22:42,710] Trial 11 finished with value: 1.0721219849607326 and parameters: {'lstm_units': 95, 'dropout_rate': 0.3754129318407822, 'learning_rate': 0.0020120774781809455, 'seq_length': 48, 'batch_size': 111}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:22:55,530] Trial 12 finished with value: 1.0459763944631895 and parameters: {'lstm_units': 100, 'dropout_rate': 0.37403342503360487, 'learning_rate': 0.0015524639773078317, 'seq_length': 39, 'batch_size': 101}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:23:08,339] Trial 13 finished with value: 1.0864125903680295 and parameters: {'lstm_units': 97, 'dropout_rate': 0.3423590947012993, 'learning_rate': 0.001393500306202316, 'seq_length': 40, 'batch_size': 104}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:23:19,593] Trial 14 finished with value: 1.0447512059146313 and parameters: {'lstm_units': 68, 'dropout_rate': 0.3843476415532252, 'learning_rate': 0.0008731774124223779, 'seq_length': 40, 'batch_size': 65}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:23:31,242] Trial 15 finished with value: 1.0331703026457528 and parameters: {'lstm_units': 67, 'dropout_rate': 0.2872975050082666, 'learning_rate': 0.00011248826199366717, 'seq_length': 41, 'batch_size': 64}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:23:42,863] Trial 16 finished with value: 1.0348670195630454 and parameters: {'lstm_units': 71, 'dropout_rate': 0.21317774676754678, 'learning_rate': 0.00010690467612554534, 'seq_length': 43, 'batch_size': 47}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:23:53,660] Trial 17 finished with value: 1.0546437497852246 and parameters: {'lstm_units': 80, 'dropout_rate': 0.29412149251433745, 'learning_rate': 0.00010647095556986193, 'seq_length': 33, 'batch_size': 73}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:24:07,292] Trial 18 finished with value: 1.0415105670325937 and parameters: {'lstm_units': 66, 'dropout_rate': 0.1564344755643105, 'learning_rate': 0.00020292481255586206, 'seq_length': 36, 'batch_size': 20}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:24:18,844] Trial 19 finished with value: 1.0500402897378793 and parameters: {'lstm_units': 91, 'dropout_rate': 0.300631815761727, 'learning_rate': 0.0005134369554962672, 'seq_length': 43, 'batch_size': 58}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:24:28,395] Trial 20 finished with value: 1.1250726745359263 and parameters: {'lstm_units': 110, 'dropout_rate': 0.4144331458743835, 'learning_rate': 0.008089011069171523, 'seq_length': 26, 'batch_size': 75}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:24:40,191] Trial 21 finished with value: 1.0380189613726292 and parameters: {'lstm_units': 74, 'dropout_rate': 0.21785304394588662, 'learning_rate': 0.00010929843700043517, 'seq_length': 44, 'batch_size': 47}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:24:54,762] Trial 22 finished with value: 1.0431830843540857 and parameters: {'lstm_units': 58, 'dropout_rate': 0.16979527959247445, 'learning_rate': 0.00016310329613719495, 'seq_length': 44, 'batch_size': 47}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:25:08,377] Trial 23 finished with value: 1.0442148310737964 and parameters: {'lstm_units': 87, 'dropout_rate': 0.2665871971561999, 'learning_rate': 0.00012990352160720814, 'seq_length': 36, 'batch_size': 46}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:25:23,220] Trial 24 finished with value: 1.037277658154743 and parameters: {'lstm_units': 74, 'dropout_rate': 0.34792416810663884, 'learning_rate': 0.0002756089256991245, 'seq_length': 43, 'batch_size': 63}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:25:39,488] Trial 25 finished with value: 1.0469242374783252 and parameters: {'lstm_units': 105, 'dropout_rate': 0.19109003867115543, 'learning_rate': 0.00037898500068328766, 'seq_length': 36, 'batch_size': 27}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:25:53,160] Trial 26 finished with value: 1.034095079500983 and parameters: {'lstm_units': 63, 'dropout_rate': 0.3241651224393347, 'learning_rate': 0.00016698654326035973, 'seq_length': 45, 'batch_size': 55}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:26:07,979] Trial 27 finished with value: 1.0474474527026663 and parameters: {'lstm_units': 61, 'dropout_rate': 0.3320714024249775, 'learning_rate': 0.0001799610893515444, 'seq_length': 45, 'batch_size': 68}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:26:21,162] Trial 28 finished with value: 1.0319075562723201 and parameters: {'lstm_units': 79, 'dropout_rate': 0.42538239075238693, 'learning_rate': 0.0006758142514133739, 'seq_length': 39, 'batch_size': 54}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:26:33,818] Trial 29 finished with value: 1.0645372465175862 and parameters: {'lstm_units': 80, 'dropout_rate': 0.4242009902359779, 'learning_rate': 0.0007508542070407971, 'seq_length': 39, 'batch_size': 99}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:26:47,294] Trial 30 finished with value: 1.0549904976535665 and parameters: {'lstm_units': 51, 'dropout_rate': 0.11933715918533222, 'learning_rate': 0.0014831647885919464, 'seq_length': 38, 'batch_size': 56}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:27:00,037] Trial 31 finished with value: 1.0516902219609616 and parameters: {'lstm_units': 62, 'dropout_rate': 0.3230197928463464, 'learning_rate': 0.00037199703620096236, 'seq_length': 41, 'batch_size': 54}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:27:14,460] Trial 32 finished with value: 1.0582784233532065 and parameters: {'lstm_units': 78, 'dropout_rate': 0.3581352366193914, 'learning_rate': 0.0011936661475920767, 'seq_length': 46, 'batch_size': 39}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:27:28,142] Trial 33 finished with value: 1.0378773133167254 and parameters: {'lstm_units': 89, 'dropout_rate': 0.2632170601932951, 'learning_rate': 0.0001457798932945084, 'seq_length': 42, 'batch_size': 63}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:27:42,647] Trial 34 finished with value: 1.091189672697143 and parameters: {'lstm_units': 48, 'dropout_rate': 0.424926311198102, 'learning_rate': 0.0021542328688017543, 'seq_length': 46, 'batch_size': 81}. Best is trial 10 with value: 1.0216786848805979.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:27:55,742] Trial 35 finished with value: 1.0210348268079932 and parameters: {'lstm_units': 66, 'dropout_rate': 0.4015403105589424, 'learning_rate': 0.00021974580103524237, 'seq_length': 48, 'batch_size': 39}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:28:06,938] Trial 36 finished with value: 1.0512189303875132 and parameters: {'lstm_units': 83, 'dropout_rate': 0.4999260114589646, 'learning_rate': 0.00023390072352365136, 'seq_length': 33, 'batch_size': 40}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:28:27,374] Trial 37 finished with value: 1.1908724593972504 and parameters: {'lstm_units': 105, 'dropout_rate': 0.3909988549018095, 'learning_rate': 0.00038411747147857836, 'seq_length': 48, 'batch_size': 20}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:28:36,968] Trial 38 finished with value: 1.1029883088038626 and parameters: {'lstm_units': 55, 'dropout_rate': 0.40784732375098687, 'learning_rate': 0.005582723048222877, 'seq_length': 29, 'batch_size': 90}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:28:50,194] Trial 39 finished with value: 1.1241211115406289 and parameters: {'lstm_units': 75, 'dropout_rate': 0.44337549862076847, 'learning_rate': 0.0006891276526312989, 'seq_length': 37, 'batch_size': 30}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:28:58,370] Trial 40 finished with value: 1.0657874568900196 and parameters: {'lstm_units': 39, 'dropout_rate': 0.2751017913385935, 'learning_rate': 0.0029120340050731606, 'seq_length': 20, 'batch_size': 117}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:29:12,273] Trial 41 finished with value: 1.028122042763644 and parameters: {'lstm_units': 67, 'dropout_rate': 0.31883667301173974, 'learning_rate': 0.0002894435579777082, 'seq_length': 46, 'batch_size': 52}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:29:22,754] Trial 42 finished with value: 1.0563481045829068 and parameters: {'lstm_units': 68, 'dropout_rate': 0.36102974985490577, 'learning_rate': 0.00031801109510215433, 'seq_length': 46, 'batch_size': 51}. Best is trial 35 with value: 1.0210348268079932.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:29:35,549] Trial 43 finished with value: 1.002343227760601 and parameters: {'lstm_units': 70, 'dropout_rate': 0.4725030557846942, 'learning_rate': 0.00022170890150768796, 'seq_length': 48, 'batch_size': 35}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:29:51,413] Trial 44 finished with value: 1.0362594429618994 and parameters: {'lstm_units': 120, 'dropout_rate': 0.4743264392361268, 'learning_rate': 0.00023255619419320443, 'seq_length': 48, 'batch_size': 36}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:30:05,787] Trial 45 finished with value: 1.0729452563920685 and parameters: {'lstm_units': 85, 'dropout_rate': 0.44989959755879433, 'learning_rate': 0.0005918913020697122, 'seq_length': 46, 'batch_size': 42}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:30:27,463] Trial 46 finished with value: 1.0428131724093872 and parameters: {'lstm_units': 92, 'dropout_rate': 0.4739322981871143, 'learning_rate': 0.001139387449383065, 'seq_length': 48, 'batch_size': 26}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:30:41,547] Trial 47 finished with value: 1.0404606859045413 and parameters: {'lstm_units': 71, 'dropout_rate': 0.4350762733531426, 'learning_rate': 0.0003273183642994851, 'seq_length': 45, 'batch_size': 34}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:30:54,565] Trial 48 finished with value: 1.055247040859484 and parameters: {'lstm_units': 78, 'dropout_rate': 0.4022244609294019, 'learning_rate': 0.0019939277594907914, 'seq_length': 47, 'batch_size': 42}. Best is trial 43 with value: 1.002343227760601.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\873535974.py:49: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:31:09,233] Trial 49 finished with value: 1.043584820307323 and parameters: {'lstm_units': 58, 'dropout_rate': 0.3706742018919459, 'learning_rate': 0.0004577535695953869, 'seq_length': 42, 'batch_size': 24}. Best is trial 43 with value: 1.002343227760601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lstm_units': 70, 'dropout_rate': 0.4725030557846942, 'learning_rate': 0.00022170890150768796, 'seq_length': 48, 'batch_size': 35}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pywt import wavedec, waverec\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Smooth the data using Exponential Moving Average (EMA)\n",
    "stock_data['Smoothed'] = stock_data['Value_diff'].ewm(span=5, adjust=False).mean()\n",
    "\n",
    "# Denoise the data using Wavelet Transform\n",
    "def wavelet_denoise(series, wavelet='db1', level=1):\n",
    "    coeff = wavedec(series, wavelet, level=level)\n",
    "    # Set detail coefficients to zero (removes noise)\n",
    "    coeff[1:] = [np.zeros_like(c) for c in coeff[1:]]\n",
    "    return waverec(coeff, wavelet)\n",
    "\n",
    "stock_data['Denoised'] = wavelet_denoise(stock_data['Value_diff'].fillna(0).values)\n",
    "\n",
    "# Replace NaNs from wavelet reconstruction\n",
    "stock_data['Denoised'] = stock_data['Denoised'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(len(stock_data) * 0.8)\n",
    "train_data = stock_data.iloc[:train_size]\n",
    "test_data = stock_data.iloc[train_size:]\n",
    "\n",
    "# Preprocess data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data['Denoised'].values.reshape(-1, 1))\n",
    "test_scaled = scaler.transform(test_data['Denoised'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the objective function for Bayesian Optimization\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lstm_units = trial.suggest_int('lstm_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    seq_length = trial.suggest_int('seq_length', 12, 48)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128)\n",
    "    \n",
    "    # Create sequences with new sequence length\n",
    "    X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "    X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Build LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(lstm_units),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=batch_size, verbose=0, validation_split=0.2)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    rmse = np.sqrt(np.mean((predictions - test_data['Value_diff'][seq_length:].values)**2))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Run Bayesian Optimization with Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lstm_units': 70, 'dropout_rate': 0.4725030557846942, 'learning_rate': 0.00022170890150768796, 'seq_length': 48, 'batch_size': 35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 587ms/step - loss: 0.1675 - val_loss: 0.0179\n",
      "Epoch 2/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0325 - val_loss: 0.0233\n",
      "Epoch 3/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0232 - val_loss: 0.0146\n",
      "Epoch 4/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0219 - val_loss: 0.0157\n",
      "Epoch 5/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0208 - val_loss: 0.0164\n",
      "Epoch 6/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0255 - val_loss: 0.0143\n",
      "Epoch 7/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0228 - val_loss: 0.0156\n",
      "Epoch 8/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0228 - val_loss: 0.0148\n",
      "Epoch 9/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0224 - val_loss: 0.0153\n",
      "Epoch 10/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0206 - val_loss: 0.0159\n",
      "Epoch 11/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 12/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0214 - val_loss: 0.0146\n",
      "Epoch 13/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0210 - val_loss: 0.0144\n",
      "Epoch 14/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 15/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0210 - val_loss: 0.0142\n",
      "Epoch 16/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0195 - val_loss: 0.0144\n",
      "Epoch 17/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0190 - val_loss: 0.0153\n",
      "Epoch 18/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 19/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 20/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0211 - val_loss: 0.0143\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "Optimized LSTM -> RMSE: 1.0017, MAE: 0.7894, MAPE: 18.7386%\n"
     ]
    }
   ],
   "source": [
    "# Extract best parameters from the Bayesian optimization study\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Create sequences using the optimized sequence length\n",
    "seq_length = best_params['seq_length']\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the final LSTM model with optimized parameters\n",
    "model = Sequential([\n",
    "    LSTM(best_params['lstm_units'], return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    LSTM(best_params['lstm_units']),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(1)\n",
    "])\n",
    "optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the final model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=best_params['batch_size'], validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate performance metrics\n",
    "actual_values = test_data['Value_diff'][seq_length:].values\n",
    "lstm_result = evaluate_model(actual_values, predictions, \"Optimized LSTM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 96ms/step - loss: 0.0793 - val_loss: 0.0147\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0190 - val_loss: 0.0143\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0179 - val_loss: 0.0142\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0164 - val_loss: 0.0174\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0168 - val_loss: 0.0205\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0170 - val_loss: 0.0139\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0163 - val_loss: 0.0139\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0179 - val_loss: 0.0138\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0174 - val_loss: 0.0138\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0163 - val_loss: 0.0154\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0171 - val_loss: 0.0135\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0181 - val_loss: 0.0141\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0153 - val_loss: 0.0132\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0153 - val_loss: 0.0130\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "Bidirectional LSTM -> RMSE: 0.9946, MAE: 0.7523, MAPE: 18.9694%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Bidirectional LSTM',\n",
       " 'RMSE': 0.9946132646017177,\n",
       " 'MAE': 0.7522855221545385,\n",
       " 'MAPE': 0.18969389442075393}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# Build Bidirectional LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(50, return_sequences=True), input_shape=(seq_length, 1)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(50)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train and Evaluate\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "predictions_bilstm = model.predict(X_test)\n",
    "predictions_bilstm = scaler.inverse_transform(predictions_bilstm)\n",
    "evaluate_model(test_data['Value_diff'][seq_length:].values, predictions_bilstm, \"Bidirectional LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:32:18,000] A new study created in memory with name: no-name-d61a50fe-9ef4-41cf-96d8-c8497b18e7e0\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:33:03,418] Trial 0 finished with value: 1.0517403359508035 and parameters: {'lstm_units': 36, 'dropout_rate': 0.3485680204898107, 'batch_size': 44, 'epochs': 49, 'seq_length': 26, 'learning_rate': 0.0009989486313994628}. Best is trial 0 with value: 1.0517403359508035.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:34:06,441] Trial 1 finished with value: 1.0832689056448375 and parameters: {'lstm_units': 78, 'dropout_rate': 0.3397427413345263, 'batch_size': 36, 'epochs': 37, 'seq_length': 35, 'learning_rate': 0.0024713490455381495}. Best is trial 0 with value: 1.0517403359508035.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:35:19,270] Trial 2 finished with value: 1.038275142547671 and parameters: {'lstm_units': 55, 'dropout_rate': 0.15447228785675096, 'batch_size': 16, 'epochs': 42, 'seq_length': 16, 'learning_rate': 0.00015063445440227226}. Best is trial 2 with value: 1.038275142547671.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:35:40,089] Trial 3 finished with value: 1.0372564730623604 and parameters: {'lstm_units': 51, 'dropout_rate': 0.13730760327496738, 'batch_size': 40, 'epochs': 11, 'seq_length': 19, 'learning_rate': 0.0002933676047049663}. Best is trial 3 with value: 1.0372564730623604.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:36:46,957] Trial 4 finished with value: 1.055766294060013 and parameters: {'lstm_units': 68, 'dropout_rate': 0.1636957709565241, 'batch_size': 25, 'epochs': 36, 'seq_length': 28, 'learning_rate': 0.000150378901450185}. Best is trial 3 with value: 1.0372564730623604.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:37:36,423] Trial 5 finished with value: 1.0380677384974144 and parameters: {'lstm_units': 84, 'dropout_rate': 0.38385363427295793, 'batch_size': 41, 'epochs': 33, 'seq_length': 16, 'learning_rate': 0.0003858348511319467}. Best is trial 3 with value: 1.0372564730623604.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:38:19,911] Trial 6 finished with value: 1.0448568882482236 and parameters: {'lstm_units': 119, 'dropout_rate': 0.4475039876730924, 'batch_size': 57, 'epochs': 23, 'seq_length': 17, 'learning_rate': 0.0005604160881572597}. Best is trial 3 with value: 1.0372564730623604.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:38:59,183] Trial 7 finished with value: 1.0393689739285001 and parameters: {'lstm_units': 64, 'dropout_rate': 0.415139601772326, 'batch_size': 25, 'epochs': 23, 'seq_length': 34, 'learning_rate': 0.00023792975785834485}. Best is trial 3 with value: 1.0372564730623604.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:40:20,888] Trial 8 finished with value: 1.0222787434955423 and parameters: {'lstm_units': 108, 'dropout_rate': 0.42955416422403436, 'batch_size': 49, 'epochs': 46, 'seq_length': 44, 'learning_rate': 6.684860282659675e-05}. Best is trial 8 with value: 1.0222787434955423.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:40:57,490] Trial 9 finished with value: 1.07842687846835 and parameters: {'lstm_units': 124, 'dropout_rate': 0.37778613840351316, 'batch_size': 21, 'epochs': 10, 'seq_length': 16, 'learning_rate': 0.0002952378806127746}. Best is trial 8 with value: 1.0222787434955423.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:42:02,304] Trial 10 finished with value: 1.0139028314095624 and parameters: {'lstm_units': 102, 'dropout_rate': 0.4939779869301941, 'batch_size': 61, 'epochs': 49, 'seq_length': 46, 'learning_rate': 1.5087691912705585e-05}. Best is trial 10 with value: 1.0139028314095624.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:43:25,572] Trial 11 finished with value: 0.9892845853089985 and parameters: {'lstm_units': 104, 'dropout_rate': 0.49000524112440874, 'batch_size': 63, 'epochs': 50, 'seq_length': 48, 'learning_rate': 1.682654391901315e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:44:38,521] Trial 12 finished with value: 1.0148474111203545 and parameters: {'lstm_units': 97, 'dropout_rate': 0.47967641099052566, 'batch_size': 64, 'epochs': 50, 'seq_length': 46, 'learning_rate': 1.20121757313604e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:45:34,234] Trial 13 finished with value: 1.0116973521422172 and parameters: {'lstm_units': 98, 'dropout_rate': 0.25956787773249546, 'batch_size': 62, 'epochs': 41, 'seq_length': 42, 'learning_rate': 1.0404473661586018e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:46:27,123] Trial 14 finished with value: 1.0075700828077179 and parameters: {'lstm_units': 91, 'dropout_rate': 0.23598262792448166, 'batch_size': 54, 'epochs': 41, 'seq_length': 40, 'learning_rate': 3.36399407017825e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:47:30,940] Trial 15 finished with value: 1.006157339922725 and parameters: {'lstm_units': 87, 'dropout_rate': 0.24458735203499446, 'batch_size': 53, 'epochs': 27, 'seq_length': 40, 'learning_rate': 4.1995921094828747e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:48:20,591] Trial 16 finished with value: 1.0302553852830034 and parameters: {'lstm_units': 113, 'dropout_rate': 0.22344434079668346, 'batch_size': 51, 'epochs': 27, 'seq_length': 37, 'learning_rate': 4.159025159854441e-05}. Best is trial 11 with value: 0.9892845853089985.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:48:50,337] Trial 17 finished with value: 0.9875876221103882 and parameters: {'lstm_units': 82, 'dropout_rate': 0.2812312387828855, 'batch_size': 57, 'epochs': 17, 'seq_length': 48, 'learning_rate': 2.7068861323038272e-05}. Best is trial 17 with value: 0.9875876221103882.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:49:15,248] Trial 18 finished with value: 0.9875325530465093 and parameters: {'lstm_units': 76, 'dropout_rate': 0.29904495454736646, 'batch_size': 58, 'epochs': 16, 'seq_length': 48, 'learning_rate': 2.3070014156420432e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:49:43,037] Trial 19 finished with value: 1.0898454583814268 and parameters: {'lstm_units': 70, 'dropout_rate': 0.29656760231738793, 'batch_size': 34, 'epochs': 16, 'seq_length': 24, 'learning_rate': 0.008683390182156806}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:50:23,410] Trial 20 finished with value: 1.0409125021130519 and parameters: {'lstm_units': 75, 'dropout_rate': 0.29898231600674474, 'batch_size': 48, 'epochs': 17, 'seq_length': 32, 'learning_rate': 6.790823407469158e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:50:48,307] Trial 21 finished with value: 0.9896596027181931 and parameters: {'lstm_units': 55, 'dropout_rate': 0.18820097707054706, 'batch_size': 57, 'epochs': 16, 'seq_length': 48, 'learning_rate': 2.6664689178497664e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:51:22,230] Trial 22 finished with value: 0.9898773839410075 and parameters: {'lstm_units': 90, 'dropout_rate': 0.32399286140491235, 'batch_size': 58, 'epochs': 20, 'seq_length': 48, 'learning_rate': 2.080987309304402e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:51:50,312] Trial 23 finished with value: 1.0181673621451799 and parameters: {'lstm_units': 106, 'dropout_rate': 0.1000675177089399, 'batch_size': 64, 'epochs': 12, 'seq_length': 44, 'learning_rate': 7.959221580549722e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:52:46,692] Trial 24 finished with value: 1.0027121383448263 and parameters: {'lstm_units': 80, 'dropout_rate': 0.2758208724199698, 'batch_size': 59, 'epochs': 29, 'seq_length': 39, 'learning_rate': 2.0120722927295376e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:53:22,339] Trial 25 finished with value: 1.01472071075401 and parameters: {'lstm_units': 62, 'dropout_rate': 0.20194351318164566, 'batch_size': 46, 'epochs': 23, 'seq_length': 43, 'learning_rate': 0.00011063027901277156}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:53:49,642] Trial 26 finished with value: 1.0006293358507001 and parameters: {'lstm_units': 45, 'dropout_rate': 0.37395964380461066, 'batch_size': 54, 'epochs': 19, 'seq_length': 48, 'learning_rate': 4.359792897166364e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:54:17,660] Trial 27 finished with value: 1.0137966892195982 and parameters: {'lstm_units': 95, 'dropout_rate': 0.31915136262786287, 'batch_size': 55, 'epochs': 14, 'seq_length': 45, 'learning_rate': 1.95544336167414e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:54:58,478] Trial 28 finished with value: 1.0089508902047963 and parameters: {'lstm_units': 71, 'dropout_rate': 0.2743374793796757, 'batch_size': 60, 'epochs': 33, 'seq_length': 41, 'learning_rate': 1.1851933221022542e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:55:47,280] Trial 29 finished with value: 1.0454448540265995 and parameters: {'lstm_units': 34, 'dropout_rate': 0.34501104509210456, 'batch_size': 44, 'epochs': 20, 'seq_length': 12, 'learning_rate': 0.0013387814752194647}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:56:19,564] Trial 30 finished with value: 1.0317209831189087 and parameters: {'lstm_units': 112, 'dropout_rate': 0.40288459309900004, 'batch_size': 50, 'epochs': 13, 'seq_length': 23, 'learning_rate': 3.0469627374292693e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:56:44,713] Trial 31 finished with value: 1.174771765649503 and parameters: {'lstm_units': 42, 'dropout_rate': 0.20708252656948595, 'batch_size': 57, 'epochs': 15, 'seq_length': 48, 'learning_rate': 2.5341653449200837e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:57:13,323] Trial 32 finished with value: 0.9899571629581734 and parameters: {'lstm_units': 57, 'dropout_rate': 0.21231455782049252, 'batch_size': 64, 'epochs': 18, 'seq_length': 48, 'learning_rate': 5.9888075560206814e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:57:54,872] Trial 33 finished with value: 1.0273092818559408 and parameters: {'lstm_units': 77, 'dropout_rate': 0.19530340990980893, 'batch_size': 35, 'epochs': 25, 'seq_length': 37, 'learning_rate': 1.5454055849014945e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:58:22,963] Trial 34 finished with value: 1.0141619283560421 and parameters: {'lstm_units': 50, 'dropout_rate': 0.15914608548202575, 'batch_size': 56, 'epochs': 21, 'seq_length': 46, 'learning_rate': 0.00010015449034618442}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 21:59:47,221] Trial 35 finished with value: 1.0115558675423164 and parameters: {'lstm_units': 58, 'dropout_rate': 0.12452387192428163, 'batch_size': 60, 'epochs': 45, 'seq_length': 43, 'learning_rate': 2.7163681441135413e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:00:51,700] Trial 36 finished with value: 1.0218245572531282 and parameters: {'lstm_units': 82, 'dropout_rate': 0.32447459228367576, 'batch_size': 52, 'epochs': 36, 'seq_length': 46, 'learning_rate': 4.8136939851290775e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:01:43,265] Trial 37 finished with value: 1.039671488171714 and parameters: {'lstm_units': 43, 'dropout_rate': 0.46254694164826055, 'batch_size': 31, 'epochs': 32, 'seq_length': 29, 'learning_rate': 0.00016672284930753208}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:02:56,184] Trial 38 finished with value: 1.0629519826795835 and parameters: {'lstm_units': 63, 'dropout_rate': 0.3527169154997861, 'batch_size': 44, 'epochs': 38, 'seq_length': 38, 'learning_rate': 0.002412450567485012}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:03:25,365] Trial 39 finished with value: 1.0782640177064744 and parameters: {'lstm_units': 50, 'dropout_rate': 0.18100887606448823, 'batch_size': 41, 'epochs': 16, 'seq_length': 34, 'learning_rate': 1.670450721856009e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:03:56,477] Trial 40 finished with value: 1.011463708988373 and parameters: {'lstm_units': 126, 'dropout_rate': 0.2757045407672686, 'batch_size': 62, 'epochs': 10, 'seq_length': 42, 'learning_rate': 2.947458579610198e-05}. Best is trial 18 with value: 0.9875325530465093.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:05:15,754] Trial 41 finished with value: 0.9857094391281777 and parameters: {'lstm_units': 90, 'dropout_rate': 0.315795149687101, 'batch_size': 58, 'epochs': 20, 'seq_length': 48, 'learning_rate': 2.1645028471729305e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:05:44,938] Trial 42 finished with value: 1.0142455985032952 and parameters: {'lstm_units': 86, 'dropout_rate': 0.24377143719458014, 'batch_size': 56, 'epochs': 13, 'seq_length': 45, 'learning_rate': 2.4124554313631134e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:06:25,796] Trial 43 finished with value: 0.9893432702488327 and parameters: {'lstm_units': 104, 'dropout_rate': 0.4343272842921991, 'batch_size': 58, 'epochs': 22, 'seq_length': 48, 'learning_rate': 1.082445992418325e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:07:07,292] Trial 44 finished with value: 1.0134444998003802 and parameters: {'lstm_units': 101, 'dropout_rate': 0.4434005418191733, 'batch_size': 62, 'epochs': 23, 'seq_length': 46, 'learning_rate': 1.458443884642872e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:07:47,272] Trial 45 finished with value: 1.0137198487510333 and parameters: {'lstm_units': 92, 'dropout_rate': 0.48559666041598487, 'batch_size': 59, 'epochs': 22, 'seq_length': 44, 'learning_rate': 1.1633970625561611e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:08:27,959] Trial 46 finished with value: 1.015856733486372 and parameters: {'lstm_units': 120, 'dropout_rate': 0.40545970776811735, 'batch_size': 47, 'epochs': 18, 'seq_length': 47, 'learning_rate': 1.566263002336427e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:10:04,789] Trial 47 finished with value: 1.0299445105101415 and parameters: {'lstm_units': 105, 'dropout_rate': 0.36203601171518085, 'batch_size': 52, 'epochs': 25, 'seq_length': 42, 'learning_rate': 0.0006520977417959952}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:11:00,277] Trial 48 finished with value: 1.0148767592706975 and parameters: {'lstm_units': 110, 'dropout_rate': 0.4751610049044635, 'batch_size': 62, 'epochs': 26, 'seq_length': 45, 'learning_rate': 1.0209627273356914e-05}. Best is trial 41 with value: 0.9857094391281777.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\4008214467.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:12:17,002] Trial 49 finished with value: 1.0178691185909687 and parameters: {'lstm_units': 101, 'dropout_rate': 0.44345957293957794, 'batch_size': 54, 'epochs': 47, 'seq_length': 44, 'learning_rate': 3.760719036504193e-05}. Best is trial 41 with value: 0.9857094391281777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lstm_units': 90, 'dropout_rate': 0.315795149687101, 'batch_size': 58, 'epochs': 20, 'seq_length': 48, 'learning_rate': 2.1645028471729305e-05}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    lstm_units = trial.suggest_int('lstm_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    seq_length = trial.suggest_int('seq_length', 12, 48)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "    # Build Bidirectional LSTM model\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=(seq_length, 1)),\n",
    "        Dropout(dropout_rate),\n",
    "        Bidirectional(LSTM(lstm_units)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with Adam optimizer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    predictions_bilstm = model.predict(X_test)\n",
    "    predictions_bilstm = scaler.inverse_transform(predictions_bilstm)\n",
    "    \n",
    "    rmse = np.sqrt(np.mean((predictions_bilstm - test_data['Value_diff'][seq_length:].values)**2))\n",
    "    \n",
    "    return rmse\n",
    "    \n",
    "\n",
    "# Create the study and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')  # Minimize RMSE\n",
    "study.optimize(objective, n_trials=50)  # Number of trials for optimization\n",
    "    \n",
    "\n",
    "# Best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lstm_units': 90, 'dropout_rate': 0.315795149687101, 'batch_size': 58, 'epochs': 20, 'seq_length': 48, 'learning_rate': 2.1645028471729305e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 217ms/step - loss: 0.2474 - val_loss: 0.3757\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1998 - val_loss: 0.2869\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1514 - val_loss: 0.2103\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1065 - val_loss: 0.1457\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0788 - val_loss: 0.0925\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0526 - val_loss: 0.0536\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0352 - val_loss: 0.0296\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0232 - val_loss: 0.0184\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0186 - val_loss: 0.0152\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0180 - val_loss: 0.0147\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0196 - val_loss: 0.0147\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0197 - val_loss: 0.0148\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0198 - val_loss: 0.0149\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0191 - val_loss: 0.0148\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0187 - val_loss: 0.0149\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0180 - val_loss: 0.0148\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0174 - val_loss: 0.0147\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0187 - val_loss: 0.0147\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0178 - val_loss: 0.0149\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "Optimized Bidirectional LSTM -> RMSE: 0.9855, MAE: 0.7828, MAPE: 18.5497%\n"
     ]
    }
   ],
   "source": [
    "# Extract the best parameters from the optimization study\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Create sequences using the optimized sequence length\n",
    "seq_length = best_params['seq_length']\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test = create_sequences(test_scaled, seq_length)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build the final Bidirectional LSTM model with optimized parameters\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(best_params['lstm_units'], return_sequences=True), input_shape=(seq_length, 1)),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Bidirectional(LSTM(best_params['lstm_units'])),\n",
    "    Dropout(best_params['dropout_rate']),\n",
    "    Dense(1)\n",
    "])\n",
    "optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Train the final model with optimized parameters\n",
    "model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions_bilstm = model.predict(X_test)\n",
    "predictions_bilstm = scaler.inverse_transform(predictions_bilstm)\n",
    "\n",
    "# Evaluate performance metrics\n",
    "bilstm_result = evaluate_model(test_data['Value_diff'][seq_length:].values, predictions_bilstm, \"Optimized Bidirectional LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - loss: 0.0930 - val_loss: 0.0195\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0164 - val_loss: 0.0152\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0164 - val_loss: 0.0156\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0170 - val_loss: 0.0162\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0173 - val_loss: 0.0150\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0144 - val_loss: 0.0168\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0143 - val_loss: 0.0186\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0171 - val_loss: 0.0156\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0142 - val_loss: 0.0153\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0148 - val_loss: 0.0171\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0159 - val_loss: 0.0152\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0160 - val_loss: 0.0156\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "Attention-LSTM -> RMSE: 1.0156, MAE: 0.7650, MAPE: 19.2704%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Attention-LSTM',\n",
       " 'RMSE': 1.0155718071657105,\n",
       " 'MAE': 0.7650269914922309,\n",
       " 'MAPE': 0.19270418675431186}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Layer\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, value = inputs, inputs  # Using self-attention\n",
    "        # Compute attention scores\n",
    "        score = tf.matmul(query, tf.transpose(value, perm=[0, 2, 1]))  # (batch_size, seq_len, seq_len)\n",
    "        score = tf.nn.softmax(score, axis=-1)  # Normalize scores\n",
    "        # Apply attention scores to the values\n",
    "        attention = tf.matmul(score, value)  # (batch_size, seq_len, features)\n",
    "        return attention\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Maintain the shape after attention\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "# Define input shape\n",
    "seq_length = X_train.shape[1]  # Assuming X_train has the shape (batch_size, seq_length, features)\n",
    "\n",
    "# Build the model\n",
    "inputs = tf.keras.Input(shape=(seq_length, 1))  # Input shape\n",
    "lstm_out = LSTM(50, return_sequences=True)(inputs)  # LSTM with return_sequences=True\n",
    "attention_out = AttentionLayer()(lstm_out)  # Single input to the custom AttentionLayer\n",
    "lstm_out2 = LSTM(50)(attention_out)  # Second LSTM processes attention output\n",
    "output = Dense(1)(lstm_out2)  # Dense layer for final output\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions_attention = model.predict(X_test)\n",
    "predictions_attention = scaler.inverse_transform(predictions_attention)\n",
    "evaluate_model(test_data['Value_diff'][seq_length:].values, predictions_attention, \"Attention-LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-12 22:13:25,211] A new study created in memory with name: no-name-3b5407f0-e454-4f2e-a073-e5a37a45eae6\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:14:00,986] Trial 0 finished with value: 0.9885582951052282 and parameters: {'lstm_units1': 85, 'lstm_units2': 78, 'learning_rate': 0.005063502038319384, 'batch_size': 16}. Best is trial 0 with value: 0.9885582951052282.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:14:28,739] Trial 1 finished with value: 0.994330293967779 and parameters: {'lstm_units1': 125, 'lstm_units2': 56, 'learning_rate': 0.0008784983368683136, 'batch_size': 32}. Best is trial 0 with value: 0.9885582951052282.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:14:43,469] Trial 2 finished with value: 0.992081886811766 and parameters: {'lstm_units1': 57, 'lstm_units2': 62, 'learning_rate': 0.0034143861527188664, 'batch_size': 64}. Best is trial 0 with value: 0.9885582951052282.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:14:54,459] Trial 3 finished with value: 1.0070830259793109 and parameters: {'lstm_units1': 34, 'lstm_units2': 37, 'learning_rate': 0.004285928409639628, 'batch_size': 128}. Best is trial 0 with value: 0.9885582951052282.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:15:07,373] Trial 4 finished with value: 0.9807137948711322 and parameters: {'lstm_units1': 36, 'lstm_units2': 44, 'learning_rate': 0.0011072413450287696, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:15:22,620] Trial 5 finished with value: 0.9951483434126266 and parameters: {'lstm_units1': 71, 'lstm_units2': 69, 'learning_rate': 0.00028462467971627776, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:16:31,418] Trial 6 finished with value: 0.9930377613307696 and parameters: {'lstm_units1': 94, 'lstm_units2': 75, 'learning_rate': 0.00037741702363354283, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:16:55,777] Trial 7 finished with value: 0.9983800554217327 and parameters: {'lstm_units1': 84, 'lstm_units2': 64, 'learning_rate': 0.0009910243557945352, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:17:19,745] Trial 8 finished with value: 0.9932209950185964 and parameters: {'lstm_units1': 41, 'lstm_units2': 78, 'learning_rate': 0.00032366539588054747, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:17:37,741] Trial 9 finished with value: 0.9965415393364733 and parameters: {'lstm_units1': 74, 'lstm_units2': 33, 'learning_rate': 0.0003064001857109813, 'batch_size': 32}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:18:10,024] Trial 10 finished with value: 1.0002228735123235 and parameters: {'lstm_units1': 106, 'lstm_units2': 113, 'learning_rate': 0.00010575919580916214, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:18:32,069] Trial 11 finished with value: 0.9887211328502348 and parameters: {'lstm_units1': 57, 'lstm_units2': 105, 'learning_rate': 0.009536496903280034, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:18:51,698] Trial 12 finished with value: 1.0024291516182278 and parameters: {'lstm_units1': 106, 'lstm_units2': 94, 'learning_rate': 0.002424304058999988, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:19:09,028] Trial 13 finished with value: 0.9887834967720188 and parameters: {'lstm_units1': 56, 'lstm_units2': 128, 'learning_rate': 0.009599962976559975, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:19:25,928] Trial 14 finished with value: 0.9880230561652704 and parameters: {'lstm_units1': 89, 'lstm_units2': 46, 'learning_rate': 0.001797941462189623, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:19:43,049] Trial 15 finished with value: 0.9885671106735648 and parameters: {'lstm_units1': 128, 'lstm_units2': 48, 'learning_rate': 0.0017510578301955016, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:19:57,341] Trial 16 finished with value: 0.9828705629002998 and parameters: {'lstm_units1': 99, 'lstm_units2': 46, 'learning_rate': 0.0015625612473265042, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:20:12,636] Trial 17 finished with value: 0.9891214557689024 and parameters: {'lstm_units1': 106, 'lstm_units2': 46, 'learning_rate': 0.0006215502863807965, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:20:28,938] Trial 18 finished with value: 0.9863124534129882 and parameters: {'lstm_units1': 115, 'lstm_units2': 52, 'learning_rate': 0.0015432114897721218, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:20:44,376] Trial 19 finished with value: 0.9899076456001641 and parameters: {'lstm_units1': 68, 'lstm_units2': 92, 'learning_rate': 0.0005716536070124257, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:21:00,675] Trial 20 finished with value: 0.9936792450841964 and parameters: {'lstm_units1': 46, 'lstm_units2': 36, 'learning_rate': 0.0010739819020024115, 'batch_size': 32}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:22:14,664] Trial 21 finished with value: 0.9879235871755613 and parameters: {'lstm_units1': 116, 'lstm_units2': 54, 'learning_rate': 0.0015043421968009793, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:22:36,514] Trial 22 finished with value: 0.9878988946804279 and parameters: {'lstm_units1': 96, 'lstm_units2': 43, 'learning_rate': 0.002388922645807933, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:22:55,290] Trial 23 finished with value: 0.986514081817015 and parameters: {'lstm_units1': 117, 'lstm_units2': 55, 'learning_rate': 0.0012499202994415805, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:23:11,307] Trial 24 finished with value: 0.9886530337938968 and parameters: {'lstm_units1': 101, 'lstm_units2': 62, 'learning_rate': 0.0006803332471370188, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:23:40,224] Trial 25 finished with value: 0.9885150053268837 and parameters: {'lstm_units1': 118, 'lstm_units2': 39, 'learning_rate': 0.002952605206689152, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:23:58,629] Trial 26 finished with value: 0.9890808917578914 and parameters: {'lstm_units1': 111, 'lstm_units2': 52, 'learning_rate': 0.006044055304596834, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:24:15,160] Trial 27 finished with value: 0.9832528533187661 and parameters: {'lstm_units1': 95, 'lstm_units2': 87, 'learning_rate': 0.0020189480928256955, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:24:38,544] Trial 28 finished with value: 1.0008214628160954 and parameters: {'lstm_units1': 78, 'lstm_units2': 88, 'learning_rate': 0.00016940567444440283, 'batch_size': 32}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:24:54,977] Trial 29 finished with value: 0.9973535442441691 and parameters: {'lstm_units1': 88, 'lstm_units2': 86, 'learning_rate': 0.005885572532330982, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:25:10,998] Trial 30 finished with value: 0.9917265533200746 and parameters: {'lstm_units1': 63, 'lstm_units2': 101, 'learning_rate': 0.0004745574552184333, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:25:32,329] Trial 31 finished with value: 0.9919709116349077 and parameters: {'lstm_units1': 96, 'lstm_units2': 71, 'learning_rate': 0.0021865775696823576, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:25:50,527] Trial 32 finished with value: 0.9891449460057292 and parameters: {'lstm_units1': 101, 'lstm_units2': 84, 'learning_rate': 0.0008544248389011734, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:26:09,426] Trial 33 finished with value: 0.9889186714710115 and parameters: {'lstm_units1': 123, 'lstm_units2': 59, 'learning_rate': 0.001357151499278915, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:26:26,394] Trial 34 finished with value: 0.9911177980335628 and parameters: {'lstm_units1': 83, 'lstm_units2': 41, 'learning_rate': 0.003741662445987058, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:26:59,138] Trial 35 finished with value: 0.9927006763142868 and parameters: {'lstm_units1': 111, 'lstm_units2': 32, 'learning_rate': 0.0007966222253886505, 'batch_size': 32}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:27:15,315] Trial 36 finished with value: 0.9915595378945925 and parameters: {'lstm_units1': 92, 'lstm_units2': 71, 'learning_rate': 0.0018196623879386555, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:28:14,957] Trial 37 finished with value: 1.0153364042078183 and parameters: {'lstm_units1': 99, 'lstm_units2': 50, 'learning_rate': 0.0010873254612553706, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:28:37,707] Trial 38 finished with value: 0.9857828033487327 and parameters: {'lstm_units1': 32, 'lstm_units2': 64, 'learning_rate': 0.0032131088796529227, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:29:13,420] Trial 39 finished with value: 0.9890270627854839 and parameters: {'lstm_units1': 32, 'lstm_units2': 64, 'learning_rate': 0.002990635478607473, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:29:27,679] Trial 40 finished with value: 0.987587557842397 and parameters: {'lstm_units1': 38, 'lstm_units2': 76, 'learning_rate': 0.0047348591271399905, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:29:45,377] Trial 41 finished with value: 0.9928173338696497 and parameters: {'lstm_units1': 42, 'lstm_units2': 61, 'learning_rate': 0.0015466298496235997, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:30:02,271] Trial 42 finished with value: 0.9927767267520102 and parameters: {'lstm_units1': 46, 'lstm_units2': 58, 'learning_rate': 0.0020892921148279926, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:30:14,345] Trial 43 finished with value: 0.9836221043804508 and parameters: {'lstm_units1': 38, 'lstm_units2': 67, 'learning_rate': 0.0031196317418469943, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:30:27,739] Trial 44 finished with value: 0.9859447109610282 and parameters: {'lstm_units1': 35, 'lstm_units2': 68, 'learning_rate': 0.0036089358957838136, 'batch_size': 128}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:30:41,831] Trial 45 finished with value: 0.9854375643144581 and parameters: {'lstm_units1': 52, 'lstm_units2': 83, 'learning_rate': 0.0028576554471069493, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:31:00,748] Trial 46 finished with value: 0.9917513394211251 and parameters: {'lstm_units1': 50, 'lstm_units2': 82, 'learning_rate': 0.007278036911559913, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:31:14,625] Trial 47 finished with value: 0.9879519187819868 and parameters: {'lstm_units1': 48, 'lstm_units2': 100, 'learning_rate': 0.0025187343009682632, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:31:29,284] Trial 48 finished with value: 0.9901162332155069 and parameters: {'lstm_units1': 41, 'lstm_units2': 93, 'learning_rate': 0.004336431941995806, 'batch_size': 64}. Best is trial 4 with value: 0.9807137948711322.\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_14152\\3048501396.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2024-12-12 22:31:47,148] Trial 49 finished with value: 0.9876480999031726 and parameters: {'lstm_units1': 53, 'lstm_units2': 80, 'learning_rate': 0.0026915944511869206, 'batch_size': 16}. Best is trial 4 with value: 0.9807137948711322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lstm_units1': 36, 'lstm_units2': 44, 'learning_rate': 0.0011072413450287696, 'batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    lstm_units1 = trial.suggest_int(\"lstm_units1\", 32, 128)\n",
    "    lstm_units2 = trial.suggest_int(\"lstm_units2\", 32, 128)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    \n",
    "    # Define the model\n",
    "    inputs = tf.keras.Input(shape=(seq_length, 1))\n",
    "    lstm_out = LSTM(lstm_units1, return_sequences=True)(inputs)\n",
    "    attention_out = AttentionLayer()(lstm_out)\n",
    "    lstm_out2 = LSTM(lstm_units2)(attention_out)\n",
    "    output = Dense(1)(lstm_out2)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "    \n",
    "    # Fit the model\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Predict and calculate validation loss\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    val_loss = mean_squared_error(test_data['Value_diff'][seq_length:].values, predictions)\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - loss: 0.1865 - val_loss: 0.0264\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0276 - val_loss: 0.0188\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0212 - val_loss: 0.0389\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0243 - val_loss: 0.0277\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0189 - val_loss: 0.0150\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0167 - val_loss: 0.0199\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0175 - val_loss: 0.0188\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0161 - val_loss: 0.0157\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0157 - val_loss: 0.0151\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0171 - val_loss: 0.0149\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0156 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0151 - val_loss: 0.0149\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0167 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0160 - val_loss: 0.0149\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0147 - val_loss: 0.0150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Optimized Attention-LSTM -> RMSE: 0.9969, MAE: 0.7852, MAPE: 18.8982%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Optimized Attention-LSTM',\n",
       " 'RMSE': 0.9968574559204572,\n",
       " 'MAE': 0.7851598641261862,\n",
       " 'MAPE': 0.18898212199723616}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "# Build the final model\n",
    "inputs = tf.keras.Input(shape=(seq_length, 1))\n",
    "lstm_out = LSTM(best_params[\"lstm_units1\"], return_sequences=True)(inputs)\n",
    "attention_out = AttentionLayer()(lstm_out)\n",
    "lstm_out2 = LSTM(best_params[\"lstm_units2\"])(attention_out)\n",
    "output = Dense(1)(lstm_out2)\n",
    "final_model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[\"learning_rate\"]), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "final_model.fit(X_train, y_train, epochs=50, batch_size=best_params[\"batch_size\"], validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions_attention = final_model.predict(X_test)\n",
    "predictions_attention = scaler.inverse_transform(predictions_attention)\n",
    "evaluate_model(test_data['Value_diff'][seq_length:].values, predictions_attention, \"Optimized Attention-LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 0.1825 - val_loss: 0.0188\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0275 - val_loss: 0.0197\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0207 - val_loss: 0.0180\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0214 - val_loss: 0.0174\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0181 - val_loss: 0.0173\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0191 - val_loss: 0.0170\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0186 - val_loss: 0.0169\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0185 - val_loss: 0.0168\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0182 - val_loss: 0.0168\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0174 - val_loss: 0.0168\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0193 - val_loss: 0.0169\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0174 - val_loss: 0.0171\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0177 - val_loss: 0.0169\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0201 - val_loss: 0.0167\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0191 - val_loss: 0.0167\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0187 - val_loss: 0.0167\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0182 - val_loss: 0.0167\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0194 - val_loss: 0.0167\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Hybrid (ARIMA + LSTM) -> RMSE: 1.5681, MAE: 1.2590, MAPE: 31.9932%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': 'Hybrid (ARIMA + LSTM)',\n",
       " 'RMSE': 1.5681186903353352,\n",
       " 'MAE': 1.2589842175921955,\n",
       " 'MAPE': 0.3199324102932488}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit ARIMA model on training data\n",
    "arima_model = ARIMA(train_data['Value_diff'], order=(1, 1, 0))\n",
    "arima_fit = arima_model.fit()\n",
    "train_arima_residuals = train_data['Value_diff'] - arima_fit.predict()\n",
    "seq_length= 48\n",
    "\n",
    "# Train LSTM on ARIMA residuals\n",
    "train_residual_scaled = scaler.fit_transform(train_arima_residuals.values.reshape(-1, 1))\n",
    "X_train, y_train = create_sequences(train_residual_scaled, seq_length)\n",
    "\n",
    "# LSTM model for residuals\n",
    "model = Sequential([\n",
    "    LSTM(79, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    Dropout(0.37920917794937004),\n",
    "    LSTM(79),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train and Evaluate\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=79, validation_split=0.2, verbose=1)\n",
    "residual_predictions = model.predict(X_test)\n",
    "residual_predictions = scaler.inverse_transform(residual_predictions)\n",
    "\n",
    "# Combine ARIMA and LSTM outputs\n",
    "arima_forecast = arima_fit.predict(start=train_size, end=len(stock_data)-1)\n",
    "final_predictions = arima_forecast.values[seq_length:] + residual_predictions.flatten()\n",
    "evaluate_model(test_data['Value_diff'][seq_length:].values, final_predictions, \"Hybrid (ARIMA + LSTM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pc\\anaconda3\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\pc\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(state_size, action_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_dim=state_size),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(action_size, activation='linear')  # Q-values for each action\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "state_size = 3  # (Value, Price_diff, Moving_avg)\n",
    "action_size = 3  # (Buy, Sell, Hold)\n",
    "batch_size = 8\n",
    "model = build_model(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(action, current_price, next_price):\n",
    "    # Buy action: Reward is the price change (profit)\n",
    "    if action == 0:  # Buy\n",
    "        return next_price - current_price\n",
    "    # Sell action: Reward is the price change (loss)\n",
    "    elif action == 1:  # Sell\n",
    "        return current_price - next_price\n",
    "    # Hold action: No reward (no change)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "# Calculate Price_diff\n",
    "stock_data['Price_diff'] = stock_data['Value_diff'].diff().fillna(0)\n",
    "\n",
    "# Calculate Moving Average (window of 10 as an example)\n",
    "stock_data['Moving_avg'] = stock_data['Value_diff'].rolling(window=10).mean().fillna(stock_data['Value_diff'].mean())\n",
    "\n",
    "\n",
    "features = stock_data[['Value_diff', 'Price_diff', 'Moving_avg']].values\n",
    "\n",
    "# Initialize experience replay memory\n",
    "memory = deque(maxlen=100)\n",
    "\n",
    "# Exploration parameters\n",
    "gamma = 0.95    # Discount factor\n",
    "epsilon = 1.0   # Exploration rate (initially explore a lot)\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# Define training loop\n",
    "for episode in range(10):  # 1000 episodes\n",
    "    state = stock_data[['Value_diff', 'Price_diff', 'Moving_avg']].iloc[0].values\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    \n",
    "    for episode in range(5):  # Reduced episodes for debugging\n",
    "        state = np.reshape(features[0], [1, state_size])\n",
    "        for t in range(1, len(features) - 1):\n",
    "            # Exploration vs Exploitation\n",
    "            if np.random.rand() <= epsilon:\n",
    "                action = random.randrange(action_size)\n",
    "            else:\n",
    "                action = np.argmax(model.predict(state, verbose=0)[0])\n",
    "\n",
    "            # Get reward and next state\n",
    "            next_state = np.reshape(features[t], [1, state_size])\n",
    "            reward = calculate_reward(action, features[t - 1][0], features[t][0])\n",
    "            memory.append((state, action, reward, next_state))\n",
    "\n",
    "\n",
    "        # Train the model using experience replay\n",
    "        # Train model using replay memory\n",
    "        if len(memory) > batch_size:\n",
    "            minibatch = random.sample(memory, batch_size)\n",
    "            states_batch = np.array([exp[0].flatten() for exp in minibatch])\n",
    "            next_states_batch = np.array([exp[3].flatten() for exp in minibatch])\n",
    "            targets = model.predict(states_batch, verbose=0)\n",
    "            next_values = model.predict(next_states_batch, verbose=0)\n",
    "            \n",
    "            for i, (state, action, reward, _) in enumerate(minibatch):\n",
    "                targets[i][action] = reward + gamma * np.amax(next_values[i])\n",
    "            model.fit(states_batch, targets, epochs=1, verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "    # Decay epsilon after each episode\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Best Actions with Positive Profit:\n",
      "Empty DataFrame\n",
      "Columns: [Timestamp, Action, Profit]\n",
      "Index: []\n",
      "Total Profit: -8714868.79565677\n"
     ]
    }
   ],
   "source": [
    "# Evaluation after training\n",
    "test_state = stock_data[['Value_diff', 'Price_diff', 'Moving_avg']].iloc[-1].values\n",
    "test_state = np.reshape(test_state, [1, state_size])\n",
    "\n",
    "# Use the trained model for prediction (test data)\n",
    "actions_taken = []\n",
    "profits = []\n",
    "recommendations = []  # To store the recommendations (Buy, Sell, Hold)\n",
    "timestamps = []  # To store the corresponding timestamps for the recommendations\n",
    "\n",
    "for t in range(len(stock_data) - 1):\n",
    "    # Predict the action for the current state\n",
    "    action = np.argmax(model.predict(test_state)[0])\n",
    "    actions_taken.append(action)\n",
    "    \n",
    "    # Calculate the reward (profit) based on the action taken\n",
    "    reward = calculate_reward(action, stock_data.iloc[t]['Value'], stock_data.iloc[t + 1]['Value_diff'])\n",
    "    profits.append(reward)\n",
    "    \n",
    "    # Store the timestamp and action recommendation\n",
    "    timestamps.append(stock_data.index[t + 1])  # Store the date of the next time step\n",
    "    if action == 0:\n",
    "        recommendations.append('Buy')  # Buy action\n",
    "    elif action == 1:\n",
    "        recommendations.append('Sell')  # Sell action\n",
    "    else:\n",
    "        recommendations.append('Hold')  # Hold action\n",
    "\n",
    "# Generate recommendation DataFrame\n",
    "recommendation_df = pd.DataFrame({\n",
    "    'Timestamp': timestamps,\n",
    "    'Action': recommendations,\n",
    "    'Profit': profits\n",
    "})\n",
    "\n",
    "# Filter recommendations to show actions with positive profits (best times to Buy/Sell)\n",
    "best_actions_df = recommendation_df[recommendation_df['Profit'] > 0]\n",
    "\n",
    "# Show recommended times to Buy, Sell, or Hold with positive profit\n",
    "print(\"Best Actions with Positive Profit:\")\n",
    "print(best_actions_df)\n",
    "\n",
    "# Evaluate performance: total profit\n",
    "total_profit = np.sum(profits)\n",
    "print(f'Total Profit: {total_profit}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
